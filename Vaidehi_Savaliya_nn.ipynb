{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDriIbfa5lwD"
      },
      "source": [
        "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvR7ppk77v31"
      },
      "source": [
        "### Importing Skin Cancer Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      },
      "source": [
        "### Importing all the important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC8xCQuELWms"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from glob import glob\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B-C_GlrxHhMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYpVPmT5z7AP"
      },
      "outputs": [],
      "source": [
        "## If you are using the data by mounting the google drive, use the following :\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D57L-ovIKtI4"
      },
      "outputs": [],
      "source": [
        "# Defining the path for train and test images\n",
        "train_path=\"/content/gdrive/MyDrive/CNN Assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train\"\n",
        "test_path=\"/content/gdrive/MyDrive/CNN Assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Test\"\n",
        "\n",
        "data_dir_train = pathlib.Path(train_path)\n",
        "data_dir_test = pathlib.Path(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqksN1w5Fu-N"
      },
      "outputs": [],
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8HkfW3jPJun"
      },
      "source": [
        "### Load using keras.preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      },
      "source": [
        "### Create a dataset\n",
        "\n",
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLfcXcZ9LjGv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5f5y43GPog1"
      },
      "source": [
        "Used 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1BWmDzr7w-5"
      },
      "outputs": [],
      "source": [
        "## Used seed=123 while creating dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train, labels='inferred', label_mode='categorical',\n",
        "    class_names=None, color_mode='rgb', batch_size=32, image_size=(180,\n",
        "    180), shuffle=True, seed=123, validation_split=0.2, subset='training',\n",
        "    interpolation='bilinear', follow_links=False, smart_resize=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYch6-SR-i2g"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train, labels='inferred', label_mode='categorical',\n",
        "    class_names=None, color_mode='rgb', batch_size=32, image_size=(180,\n",
        "    180), shuffle=True, seed=123, validation_split=0.2, subset='validation',\n",
        "    interpolation='bilinear', follow_links=False, smart_resize=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk0RV7G7-nad"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsm5oYiQH_b"
      },
      "source": [
        "### Visualizing the data #### "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKILZ48I-q1k"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9): \n",
        "  plt.subplot(3, 3, i + 1)\n",
        "  image = mpimg.imread(str(list(data_dir_train.glob(class_names[i]+'/*.jpg'))[1]))\n",
        "  plt.title(class_names[i])\n",
        "  plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzVXBHiyQ7_I"
      },
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wZlKRBEGNtU"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      },
      "source": [
        "*italicized text*### Creating the model####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ync9xoW7GZgn"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3),offset=0.0),\n",
        "\n",
        "  layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.1),\n",
        "\n",
        "  layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.1),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.25),\n",
        "  layers.Dense(9, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      },
      "source": [
        "### Compile the model\n",
        "Choosing an appropirate optimiser and loss function for model training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB8wKtiPGe1j"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljD_83rwSl5O"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkfw2rJXGlYC"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3679V8OShSE"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1xkgk5nGubz"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRTPbJEn-pX"
      },
      "source": [
        "### Write your findings here\n",
        "##### > As we can see that Training accuracy is 91 percent and validation accuracy is 77 percent as this is a  clear case of overfitting\n",
        "##### > And also the validation loss is high.\n",
        "##### > To increase model accuracy we can use dropout layers and batch normalization .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22hljAl6GykA"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "\n",
        "data_augmentation=tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\",input_shape=(img_height,img_width,3)),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEjPWh8GG0C7"
      },
      "outputs": [],
      "source": [
        "# visualizing how augmentation strategy works for one instance of training image.\n",
        "# Your code goes here\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(data_augmentation(images)[i].numpy().astype(\"uint8\"))\n",
        "        #plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKDHlUdTuSX"
      },
      "source": [
        "\n",
        "### Create the model, compile and train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3V4l-O9G3dM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model_augmented = Sequential([\n",
        "  data_augmentation,layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3),offset=0.0),\n",
        "\n",
        "  layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.5),\n",
        "\n",
        "  layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.5),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.25),\n",
        "  layers.Dense(9, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUWFp96UIAN"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-7yTm8IG8zR"
      },
      "outputs": [],
      "source": [
        "model_augmented.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC-D_RWOURp6"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcPfkUASHBf9"
      },
      "outputs": [],
      "source": [
        "## Your code goes here, note: train your model for 20 epochs\n",
        "history =model_augmented.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ") ## your training code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhNOKtSyUYzC"
      },
      "source": [
        "### Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjN_F4QxHIsh"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-AUR_b7UcaK"
      },
      "source": [
        "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?\n",
        "\n",
        "##### > Overfitting problem is solved by the augumented model \n",
        "##### > Class imbalance Problem should be checked to improve the model accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TdDi4u-VTkW"
      },
      "source": [
        "#### **Todo:** Find the distribution of classes in the training dataset.\n",
        "#### **Context:** Many times real life datasets can have class imbalance,fore example one class can have proportionately higher number of samples as compared to the others. Class imbalance may give a detrimental effect on the final model quality. so that a sanity check becomes important to do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAhwYgtTQRzq"
      },
      "outputs": [],
      "source": [
        "## Your code goes here.\n",
        "\n",
        "for i in class_names:\n",
        "    directory =train_path+i+'/'\n",
        "    class_directory = pathlib.Path(directory)\n",
        "    length=len(list(class_directory.glob('*.jpg')))\n",
        "    print(f'{i} has {length} samples.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csQL1dvO0b2"
      },
      "source": [
        "#### **Todo:** Write your findings here: \n",
        "#### - Which class has the least number of samples?\n",
        "##### **> seborrheic keratosis has least number of samples**\n",
        "#### - Which classes dominate the data in terms proportionate number of samples?\n",
        "#####**>pigmented benign keratosis class dominates the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-stKyHPf8v"
      },
      "source": [
        "#### **Todo:** Rectify the class imbalance\n",
        "#### **Context:** You can use a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItAg4rU-SzJh"
      },
      "outputs": [],
      "source": [
        "!pip install Augmentor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZKzTe3zWL4O"
      },
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipelineâ€™s` `sample()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_training_dataset= \"/content/gdrive/MyDrive/CNN Assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n"
      ],
      "metadata": {
        "id": "2jV-gqlgiZq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Egt9EHjR-Dd"
      },
      "outputs": [],
      "source": [
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBIFZGbWuFa"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxWcMqZhdRWz"
      },
      "outputs": [],
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      },
      "source": [
        "### Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tODrYIY2nxJ"
      },
      "outputs": [],
      "source": [
        "path_list = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZvVdF7g3E1z"
      },
      "outputs": [],
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "lesion_list_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okcqVFAA2nxK"
      },
      "outputs": [],
      "source": [
        "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j45rmxd2nxK"
      },
      "outputs": [],
      "source": [
        "for i in class_names:\n",
        "    directory =train_path+i+'/'\n",
        "    directory_out =train_path+i+'/output/'\n",
        "    class_directory = pathlib.Path(directory)\n",
        "    class_directory_out = pathlib.Path(directory_out)\n",
        "    length=len(list(class_directory.glob('*.jpg')))\n",
        "    length_out=len(list(class_directory_out.glob('*.jpg')))\n",
        "    length_tot=length+length_out\n",
        "    print(f'{i} has {length_tot} samples.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnspeMbRWNs"
      },
      "source": [
        "#### **Todo**: Train the model on the data created using Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFcj1XgndRWz"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0haOU11Ey8ey"
      },
      "source": [
        "#### **Todo:** Create a training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4ZY11judRWz"
      },
      "outputs": [],
      "source": [
        "data_dir_train=train_path\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123, label_mode='categorical',\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwNJVDuBP5kf"
      },
      "source": [
        "#### **Todo:** Create a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX191d_3dRW0"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123, label_mode='categorical',\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaoWeOEpVjqH"
      },
      "source": [
        "#### **Todo:** Create your model (make sure to include normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch0MuKvFVr7O"
      },
      "outputs": [],
      "source": [
        "## your code goes here\n",
        "\n",
        "model_final = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3),offset=0.0),\n",
        "\n",
        "  layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.25),\n",
        "\n",
        "  layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.25),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Dense(9, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      },
      "source": [
        "#### **Todo:** Compile your model (Choose optimizer and loss function appropriately)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47GWmLbdRW1"
      },
      "outputs": [],
      "source": [
        "## your code goes here\n",
        "model_final.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      },
      "source": [
        "#### **Todo:**  Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcV6OdI4dRW1"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "## Your code goes here, use 50 epochs.\n",
        "history = model_final.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuvfCTsBWLMp"
      },
      "source": [
        "#### **Todo:**  Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCTXwfkTdRW1"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way4lakC4_p0"
      },
      "source": [
        "#### **Todo:**  Analyze your results here. Did you get rid of underfitting/overfitting? Did class rebalance help?\n",
        "\n",
        "> Yes the overfitting is balanced with the help of Dropout layer\n",
        "> Class Rebalance helped to improve the accuracy of the data.\n",
        "> From all the models the goof fit with around 80% accuracy and low loss comparitively \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}